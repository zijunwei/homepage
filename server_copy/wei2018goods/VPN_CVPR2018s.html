<!DOCTYPE html>
<html lang="en">
<head>
  <title>Good View Hunting: Learning Photo Composition from Dense View Pairs</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="author" content="owwwlab.com">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta name="description" content="project page" />
  <meta name="keywords" content="theme,css, html, jquery, transition, transform, 3d, css3" />

  <link rel="shortcut icon" href="../favicon.ico">

  <!--CSS styles-->
  <link rel="stylesheet" href="css/bootstrap.css">
  <link rel="stylesheet" href="css/font-awesome.min.css">
  <link rel="stylesheet" href="css/perfect-scrollbar-0.4.5.min.css">
  <link rel="stylesheet" href="css/magnific-popup.css">
  <link rel="stylesheet" href="css/style.css">
  <link id="theme-style" rel="stylesheet" href="css/styles/default.css">


  <!--/CSS styles-->
  <!--Javascript files-->
  <script type="text/javascript" src="js/jquery-1.10.2.js"></script>
  <script type="text/javascript" src="js/TweenMax.min.js"></script>
  <script type="text/javascript" src="js/jquery.touchSwipe.min.js"></script>
  <script type="text/javascript" src="js/jquery.carouFredSel-6.2.1-packed.js"></script>

  <script type="text/javascript" src="js/modernizr.custom.63321.js"></script>
  <script type="text/javascript" src="js/jquery.dropdownit.js"></script>

  <script type="text/javascript" src="js/jquery.stellar.min.js"></script>
  <script type="text/javascript" src="js/ScrollToPlugin.min.js"></script>

  <script type="text/javascript" src="js/bootstrap.min.js"></script>

  <script type="text/javascript" src="js/jquery.mixitup.min.js"></script>

  <script type="text/javascript" src="js/masonry.min.js"></script>

  <script type="text/javascript" src="js/perfect-scrollbar-0.4.5.with-mousewheel.min.js"></script>

  <script type="text/javascript" src="js/magnific-popup.js"></script>
  <script type="text/javascript" src="js/custom.js"></script>

  <!--/Javascript files-->

</head>
<body>

  <!-- <div id="wrapper"> -->
  <!-- <a href="#sidebar" class="mobilemenu"><i class="icon-reorder"></i></a> -->

  <!-- <div id="sidebar">
  <div id="main-nav">
  <div id="nav-container">
  <div id="profile" class="clearfix">
  <div class="portrate hidden-xs"></div>
  <div class="title">
  <!-- <h3>Computer Vision Lab</h3> -->
  <!-- <img src="img/Stony-Brook-University-seal.jpg" alt="HTML5 Icon" style="width:128px;height:128px;"> -->
  <!-- <h3>Stony Brook Univeristy</h3> -->
  <!-- <h2>Links </h2> -->
  <!-- </div>

</div>
<ul id="navigation"> -->

<!-- <li>
<a href="index.html">
<div class="icon icon-user"></div>
<div class="text">Zijun Wei</div>
</a>
</li>

<li>
<a href="http://www3.cs.stonybrook.edu/~minhhoai/">
<div class="icon icon-user"></div>
<div class="text">Minh Hoai</div>
</a>
</li> -->

<!-- <li>
<a href="http://www3.cs.stonybrook.edu/~cvl/">
<div class="icon icon-eye-open"></div>
<div class="text">Computer Vision Lab</div>
</a>
</li>
</ul>
</div>
</div> -->


</div> -->

<!-- <div id="main"> -->
<!-- <div id="research" class="page"> -->
<div class="pageheader">

  <div class="headercontent">

    <div class="section-container">
      <h1 class="text-center" ><strong> Good View Hunting: Learning Photo Composition from Dense View Pairs </strong> </h1>
      <div class="col-md-8 col-md-offset-2">


        <!-- <h3 class=" text-center" ><a href="index.html"> Zijun Wei </a><sup>1</sup>,
        	&nbsp&nbsp<a href="https://jimmie33.github.io/">Jianming Zhang</a><sup>2</sup>,
        	&nbsp&nbsp<a href="http://users.eecs.northwestern.edu/~xsh835/">Xiaohui Shen</a><sup>2</sup>,
        	&nbsp&nbsp<a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a><sup>2</sup>,
        	&nbsp&nbsp<a href="https://research.adobe.com/person/radomir-mech/">Radom&#237;r M&#283;ch</a><sup>2</sup>,
        	&nbsp&nbsp<a href="http://www3.cs.stonybrook.edu/~minhhoai/">Minh Hoai</a><sup>1</sup>,
        	&nbsp&nbsp<a href="http://www3.cs.stonybrook.edu/~samaras/">Dimitris Samaras</a><sup>1</sup>  </h3>

        <div class="title text-center">  <h3>1. Stony Brook University; 2. Adobe Research</h3>  </div> -->
      </div>
    </div>
  </div>

</div>
<div class="pagecontents">

  <div class="section color-1">
    <div class="section-container">
      <div class="row">
        <div class="col-md-8 col-md-offset-2">
          <h3 class=" text-center" ><a href="http://www.zijunwei.org/"> Zijun Wei </a><sup>1</sup>,
          	&nbsp&nbsp<a href="https://jimmie33.github.io/">Jianming Zhang</a><sup>2</sup>,
          	&nbsp&nbsp<a href="http://users.eecs.northwestern.edu/~xsh835/">Xiaohui Shen</a><sup>2</sup>,
          	&nbsp&nbsp<a href="https://research.adobe.com/person/zhe-lin/">Zhe Lin</a><sup>2</sup>,
          	&nbsp&nbsp<a href="https://research.adobe.com/person/radomir-mech/">Radom&#237;r M&#283;ch</a><sup>2</sup>,
          	&nbsp&nbsp<a href="http://www3.cs.stonybrook.edu/~minhhoai/">Minh Hoai</a><sup>1</sup>,
          	&nbsp&nbsp<a href="http://www3.cs.stonybrook.edu/~samaras/">Dimitris Samaras</a><sup>1</sup>  </h3>

          <div class="title text-center">  <h3>1. Stony Brook University; 2. Adobe Research</h3>  </div>

        </div>
      </div>
    </div>
  </div>
<div class="pagecontents">

  <div class="section color-2">
    <div class="section-container">
      <div class="row">
        <div class="col-md-8 col-md-offset-2">

          <div class="title text-center">
            <h2>Abstract</h2>
          </div>
          <h3> Finding views with good photo composition is a challenging task for machine learning methods.  A key difficulty is the lack of well annotated large scale datasets. Most existing datasets only provide a limited number of annotations for good views, while ignoring the comparative nature of view selection. In this work, we present the first large scale Comparative Photo Composition dataset, which contains over one million comparative view pairs annotated using a cost-effective crowdsourcing workflow. We show that these comparative view annotations are essential for training a robust neural network model for composition. In addition, we propose a novel knowledge transfer framework to train a fast view proposal network, which runs at 75+ FPS and achieves state-of-the-art performance in image cropping and thumbnail generation tasks on three benchmark datasets. The superiority of our method is also demonstrated in a user study on a challenging experiment, where our method significantly outperforms the baseline methods in producing diversified well-composed views.</h3>
        </div>
      </div>
    </div>
  </div>


  <div class="section color-2">
    <div class="section-container">
      <div class="row">
        <div class="col-md-8 col-md-offset-2">
          <div class="title text-center">

            <img src="img/projects/CVPR2018/teaser.png" alt="HTML5 Icon" align="middle" style="width:100%;height:100%;">
            <h3>Real-time suggestions for different stories over different aspect ratios </h3>
          </div>
        </div>
      </div>
    </div>
  </div>


  <div class="section color-1">
    <div class="section-container">
      <div class="row">
        <div class="col-md-8 col-md-offset-2">

          <div class="title text-center">
            <h2>Contributions</h2>
          </div>
          <ul class="ul-boxed list-unstyled">
                                          <li>Two datasets with dense views comparisons &nbsp&nbsp<span class="label label-warning">[See Resources]</span></li>
                                          <li>A <strong>robust</strong> view evaluation network</li>
                                          <li>A <strong>real-time </strong>view proposal network</li>
          </ul>
        </div>
      </div>
    </div>
  </div>


  <div class="section color-2">
    <div class="section-container">
      <div class="row">
        <div class="col-md-8 col-md-offset-2">
          <div class="title text-center">
              <h2>Sample Results</h2>
             <img src="img/projects/CVPR2018/examples.png" alt="HTML5 Icon" align="middle" style="width:100%;height:100%;">
          </div>
        </div>
      </div>
    </div>
  </div>

    <div class="section color-1">
      <div class="section-container">
        <div class="row">
          <div class="col-md-8 col-md-offset-2">
            <div class="title text-center">
              <h2>Resources</h2>
            </div>
            <ul class="ul-boxed list-unstyled">
                                            <li><a href="papers/RRSVM_CVPR16_final.pdf">Paper</a> &nbsp&nbsp<span class="label label-warning">[coming soon]</span>  </li>
                                            <li><a href="papers/RRSVM_CVPR16_final.pdf">ArXiv</a> &nbsp&nbsp<span class="label label-warning">[coming soon]</span> </li>
                                            <li><a href="https://drive.google.com/open?id=1TMvuCSONEN1_9y7KnzKgy_7_fSFTHzyO">CPCDataset</a></li>
                                            <li><a href="https://drive.google.com/open?id=1DpNY_Fb9eCabwROYF02eMzy4gK3I4Pzj">XPViewDataset</a></li>
                                            <li><a href="https://github.com/zijunwei/Region-Ranking-SVM">View Proposal Net (VPN)</a> &nbsp&nbsp<span class="label label-warning">[coming soon]</span></li>
                                            <li><a href="https://github.com/zijunwei/Region-Ranking-SVM">View Evaluation Net (VEN)</a> &nbsp&nbsp<span class="label label-warning">[coming soon]</span></li>
                                            <li><a href="https://drive.google.com/open?id=1IXBtvwn8fMCmDRczQExIR3ZSDhinoqbi">Pretrained Models</a></li>
                                        </ul>


            </div>
          </div>
        </div>
      </div>


<!--     <div class="section color-2">
      <div class="section-container">
        <div class="row">
          <div class="col-md-10 col-md-offset-1">
            <div class="title text-center">
              <h2>View RRSVM in Another Perspective</h2>

            <img src="img/projects/RRSVM_more.png" alt="HTML5 Icon" align="middle" style="width:100%;height:100%;">
            <div >
              <h3><strong> The evolution of top-rank regions and region scores:</strong> </h3>
              <p> From left to right:some image regions and corresponding scores (from the base classifier) at iterations 1, 3, 6, and 9. </p>
              <p> (a) for each iteration, the regions at ranks 1, 3, 5 and their scores are shown. For clarity, we list the region scores and region weights underneath each image.</p>
              <p> (b,c): the scores of the same set of regions through iterations. The regions in (b) are the ones that are ranked 1, 3, 5 at the first iteration. In (c) are the regions that are ranked 1, 3, 5 after convergence.</p>
            </div>

          </div>
        </div>
      </div>
    </div> -->

<!--     <div class="section color-1">
      <div class="section-container">
        <div class="row">
          <div class="col-md-10 col-md-offset-1">
            <div class="title text-center">
              <h2>Acknowlegement</h2>
            </div>
            <h3>This project is partially supported by the National Science Foundation Award IIS-1566248 and IIS-1161876. </h3>
            <h3>We thank <a href="http://alantian.net/"> Yingtao Tian</a> for providing GPU resources. We also thank Yang Wang and Boyu Wang for helpful discussions and useful feedbacks.</h3>

          </div>
        </div>
      </div>
    </div> -->


      <div class="section color-2">
        <div class="section-container">
          <div class="row">
            <div class="col-md-8 col-md-offset-2">
              <div class="title text-center">
                <h2>Reference</h2>
              </div>
              <h3><strong>Good View Hunting: Learning Photo Composition from Dense View Pairs.</strong></h3>

                  <h3>Wei, Z., Zhang, Z., Shen, X., Lin, Z., Mech, R., Hoai, M. and Samaras, D. (2018)</h3>
                  <h3><i>Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR). </i></h3>

                  <h2>Bibtex</h2>
                  <h4>@inproceedings{wei2018good,</h4>
                  <h4>Author = {Zijun Wei and Jianming Zhang and Xiaohui Shen and Zhe Lin and Radomir Mech and Minh Hoai and Dimitris Samaras},</h4>
                  <h4>Booktitle = {Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},</h4>
                  <h4>Title = {Good View Hunting: Learning Photo Composition from Dense View Pairs},</h4>
                  <h4>Year = {2018}</h4>
                  <h4>}</h4>
              </div>
            </div>
          </div>
        </div>

  </div>


</body>
</html>
